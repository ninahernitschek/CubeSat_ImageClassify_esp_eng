{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d96022-6e30-4931-b70f-1d3aee0745e0",
   "metadata": {},
   "source": [
    "# Notebook 2: Reading Data / Notebook 2: Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7ce69-b1fa-4046-ad3a-868aa6b3404f",
   "metadata": {},
   "source": [
    "Welcome! The main goal of this notebook is to read the Cubeset data and explore its characteristics.\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "¡Bienvenido! El objetivo principal de este cuaderno es leer los datos de Cubeset y explorar sus características.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5059112-490b-4c53-9c84-489bd09d5316",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c83716",
   "metadata": {},
   "source": [
    "#### Importing libraries / Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing Matplotlib for creating visualizations and plots.\n",
    "# Importación de Matplotlib para crear visualizaciones y gráficos.\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Importing the 'random' module for generating random numbers and making random selections.\n",
    "# Importar el módulo 'random' para generar números aleatorios y hacer selecciones aleatorias.\n",
    "import random  \n",
    "\n",
    "# Importing NumPy, a library for numerical operations, used here for handling and manipulating image data arrays.\n",
    "# Importación de NumPy, una biblioteca para operaciones numéricas, utilizada aquí para manejar y manipular matrices de datos de imagen.\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac2a4f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f606b",
   "metadata": {},
   "source": [
    "### Reading the data from **Numpy** / Leer los datos con **Numpy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c53d6",
   "metadata": {},
   "source": [
    "In the `data` folder, you will find three types of datasets, each saved as numpy files along with their corresponding label files. These datasets are organized as follows:\n",
    "\n",
    "1. `train_images.npy`: Contains images used for **training** machine and deep learning models. The associated labels are stored in train_labels.npy.\n",
    "2. `val_images.npy`: Contains images used for **validating** the trained models. The corresponding labels are stored in val_labels.npy.\n",
    "3. `test_images.npy`: Contains images used for **testing** the trained models. The associated labels are stored in test_labels.npy.\n",
    "\n",
    "Let's now read and explore these datasets.\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    "    \n",
    "\n",
    "En la carpeta `data`, encontrarás tres tipos de conjuntos de datos, cada uno guardado como archivos numpy junto con sus correspondientes archivos de etiquetas. Estos conjuntos de datos están organizados de la siguiente manera\n",
    "\n",
    "1. `train_images.npy`: Contiene imágenes utilizadas para **entrenar** modelos de aprendizaje automático y profundo. Las etiquetas asociadas se almacenan en train_labels.npy.\n",
    "2. 2. `val_images.npy`: Contiene imágenes utilizadas para **validar** los modelos entrenados. Las etiquetas correspondientes se almacenan en val_labels.npy.\n",
    "3. `test_images.npy`: Contiene imágenes utilizadas para **probar** los modelos entrenados. Las etiquetas correspondientes se almacenan en test_labels.npy.\n",
    "\n",
    "Ahora vamos a leer y explorar estos conjuntos de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75171954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the datasets /  Cargar los conjuntos de datos\n",
    "train_images = np.load('data/train_images.npy')\n",
    "train_labels = np.load('data/train_labels.npy')\n",
    "val_images = np.load('data/val_images.npy')\n",
    "val_labels = np.load('data/val_labels.npy')\n",
    "test_images = np.load('data/test_images.npy')\n",
    "test_labels = np.load('data/test_labels.npy')\n",
    "\n",
    "# Print basic information about each dataset /  Imprimir información básica sobre cada conjunto de datos\n",
    "print(f\"Training images: {train_images.shape}, Training labels: {train_labels.shape}\")\n",
    "print(f\"Validation images: {val_images.shape}, Validation labels: {val_labels.shape}\")\n",
    "print(f\"Testing images: {test_images.shape}, Testing labels: {test_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ec165c",
   "metadata": {},
   "source": [
    "The training dataset consists of 9,711 samples of 512x512 RGB images, while the validation and testing sets each contain 3,237 samples.\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    "    \n",
    "\n",
    "El conjunto de datos de entrenamiento (training set) consta de 9.711 muestras de imágenes RGB de 512x512, mientras que los conjuntos de validación y prueba contienen 3.237 muestras cada uno.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7069c0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d91fd",
   "metadata": {},
   "source": [
    "### Visualising the data /  Visualizar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d95d4-1c54-40dc-9546-e9f9b95ee932",
   "metadata": {},
   "source": [
    "The dataset we will be working with contains five classes, described as follows:\n",
    "- **Blurry**: Data captured while the satellite is in motion, resulting in blurred images.\n",
    "- **Corrupt**: Images with defects from improper camera priming or stray light.\n",
    "- **Missing Data**: Images with partial or complete data loss.\n",
    "- **Noisy**: Images over-saturated with noise from radiation or other sources.\n",
    "- **Priority**: Clear images suitable for scientific analysis on the ground.\n",
    "\n",
    "Now, Let’s take a look at these datasets.\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    " \n",
    "El conjunto de datos con el que trabajaremos contiene cinco clases, que se describen a continuación:\n",
    "- **Borrosa** (Blurry): Datos capturados mientras el satélite está en movimiento, lo que da lugar a imágenes borrosas.\n",
    "- **Corruptas** (Corrupt): Imágenes con defectos debidos a un cebado incorrecto de la cámara o a luz parásita.\n",
    "- **Datos perdidos** (Missing data): Imágenes con pérdida parcial o total de datos.\n",
    "- **Ruido** (Noisy): Imágenes sobresaturadas de ruido por radiación u otras fuentes.\n",
    "- **Prioridad** (Priority): Imágenes nítidas aptas para el análisis científico sobre el terreno.\n",
    "\n",
    "Ahora, echemos un vistazo a estos conjuntos de datos.\n",
    "\n",
    "(En el código, utilizaremos el términos ingléses.\n",
    "También mantenemos los comentarios del código en inglés después de la primera introducción. Esto le ayudará a preparar su presentación, que debe ser en inglés. Si es necesario, comuníquese con sus compañeros de equipo y utilice un traductor en línea como www.deepl.com.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class names\n",
    "class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
    "\n",
    "# Get the unique labels in the training set\n",
    "unique_labels = np.unique(train_labels)\n",
    "\n",
    "\n",
    "# Display the first 5 images for each class\n",
    "for label in unique_labels:\n",
    "    # Find the indices of images belonging to the current class\n",
    "    class_indices = np.where(train_labels == label)[0]\n",
    "    \n",
    "    # Select the first 5 images of this class\n",
    "    num_images_to_display = min(5, len(class_indices))\n",
    "    selected_indices = class_indices[:num_images_to_display]\n",
    "    selected_images = train_images[selected_indices] / 255.0  # Normalize images for better visualization\n",
    "\n",
    "    # Plot the selected images\n",
    "    fig, axes = plt.subplots(1, num_images_to_display, figsize=(20, 4))\n",
    "    fig.suptitle(f'Class: {class_names[label]}', fontsize=16)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(selected_images[i])\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed968bf9",
   "metadata": {},
   "source": [
    "The images in the dataset appear to have distinct visual characteristics that make them easy to classify by eye. For example, “Blurry,” “Corrupt” and “Missing Data” images each have unique visual patterns and anomalies that differentiate them from one another. Given these clear differences, we can reasonably expect that machine learning models would also be able to classify these images with high accuracy, as the features that distinguish each class are visually pronounced and easily identifiable.\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "Las imágenes del conjunto de datos parecen tener características visuales distintas que facilitan su clasificación a simple vista. Por ejemplo, las imágenes «Blurry», «Corrupt» y «Missing Data» presentan patrones visuales únicos y anomalías que las diferencian unas de otras. Dadas estas claras diferencias, podemos esperar razonablemente que los modelos de aprendizaje automático también sean capaces de clasificar estas imágenes con gran precisión, ya que las características que distinguen cada clase son visualmente pronunciadas y fácilmente identificables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd324d",
   "metadata": {},
   "source": [
    "If we were to rank these images in terms of importance based on their significance in capturing and transmitting them back to Earth, the order would be:\n",
    "\n",
    "1. `Priority`: Images with the highest importance and usability.\n",
    "2. `Noisy` & `Blurry`: Impure images that are potentially recoverable with preprocessing.\n",
    "3. `Corrupt` and `Missing Data`: Images with severe issues or missing information, making recovery or reuse least likely.\n",
    "\n",
    "This ranking will help assess model performance by testing its ability to handle different levels of data quality and recover meaningful information from problematic images.\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    "\n",
    "    \n",
    "Si tuviéramos que categorizar estas imágenes en función de su importancia para captarlas y transmitirlas de vuelta a la Tierra, el orden sería:\n",
    "\n",
    "1. `Priority`: Imágenes con mayor importancia y utilidad.\n",
    "2. `Noisy` & `Blurry`: Imágenes impuras que son potencialmente recuperables con preprocesamiento.\n",
    "3. `Corrupt` and `Missing Data`: Imágenes con problemas graves o a las que les falta información, por lo que su recuperación o reutilización es menos probable.\n",
    "    \n",
    "Esta categorización ayudará a evaluar el rendimiento del modelo poniendo a prueba su capacidad para manejar distintos niveles de calidad de los datos y recuperar información significativa de imágenes problemáticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7d31c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7f142",
   "metadata": {},
   "source": [
    "### Class Balance Check / Comprobación del saldo de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9860b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of the classes in each dataset\n",
    "train_class_counts = np.bincount(train_labels)\n",
    "val_class_counts = np.bincount(val_labels)\n",
    "test_class_counts = np.bincount(test_labels)\n",
    "\n",
    "# Display the class distribution with class names\n",
    "print(\"\\nClass distribution:\")\n",
    "print(f\"Training set: {dict(zip(class_names, train_class_counts))}\")\n",
    "print(f\"Validation set: {dict(zip(class_names, val_class_counts))}\")\n",
    "print(f\"Testing set: {dict(zip(class_names, test_class_counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa2c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "The `Priority` class has the most data, followed by `Noisy` and `Blurry`, while `Corrupt` has the least, indicating class imbalance.\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    "\n",
    "    La clase `Priority` es la que tiene más datos, seguida de `Noisy` y `Blurry`, mientras que `Corrupt` es la que tiene menos, lo que indica un desequilibrio de clases.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5a47c-b6b0-4948-ab8f-0f6b0db0530f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f94df-fad7-4384-8f39-07c6ea2a42f8",
   "metadata": {},
   "source": [
    "### Finally, removing data from memory / Por último, eliminar datos de la memoria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd31cb4-ea77-45bf-86ac-bf1c5e7510e6",
   "metadata": {},
   "source": [
    "**⚠️ Important Notice**: Since this code is being executed in a shared environment (ilifu), freeing up memory is crucial to ensure efficient resource usage. By removing unused data, it helps prevent memory bottlenecks that could affect not only your work but also the performance of other users relying on the shared hardware. This is especially important when working with large datasets (like in our case), as excessive memory usage can slow down the overall system and reduce availability for others using the same resources.\n",
    "\n",
    "**Make sure to follow this same practice when you develop your own pipeline during the hackathon to optimize performance and resource allocation.**\n",
    "\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "**⚠️ Aviso importante**: Dado que este código está siendo ejecutado en un entorno compartido (ilifu), liberar memoria es crucial para asegurar un uso eficiente de los recursos. Al eliminar los datos no utilizados, ayuda a prevenir cuellos de botella de memoria que podrían afectar no sólo a su trabajo, sino también el rendimiento de otros usuarios que dependen del hardware compartido. Esto es especialmente importante cuando se trabaja con grandes conjuntos de datos (como en nuestro caso), ya que el uso excesivo de memoria puede ralentizar el sistema en general y reducir la disponibilidad para otros que utilizan los mismos recursos.\n",
    "\n",
    "**Asegúrate de seguir esta misma práctica cuando desarrolles tu propio pipeline durante el hackathon para optimizar el rendimiento y la asignación de recursos.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919afa30-eff6-4a3c-b670-47c3675f0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Remove the data from memory\n",
    "del train_images, train_labels, val_images, val_labels, test_images, test_labels\n",
    "\n",
    "# Force garbage collection to free up memory\n",
    "gc.collect()\n",
    "\n",
    "# Clear the input/output cache\n",
    "print(\"Data removed from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7b16d-5c01-470f-bd3c-fc2b9db0d492",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159bffc2-f9fd-405b-a934-7947a1939059",
   "metadata": {},
   "source": [
    "**⚠️ When you are done, make sure to restart the notebooks**\n",
    "\n",
    "\n",
    " <hr style=\"border:2px solid gray\">\n",
    " \n",
    "**⚠️ Cuando hayas terminado, asegúrate de reiniciar los Notebooks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9fc6e-470c-4d2a-b526-4308e0be5071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
